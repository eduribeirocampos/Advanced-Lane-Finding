{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import glob\n",
    "import pickle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera Calibration with Open CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Arrays to store objects points and image points from all the images\n",
    "\n",
    "objpoints = [] #3D points in real world space\n",
    "imgpoints = [] #2D points in image plane\n",
    "\n",
    "#Prepare object points, like (0,0,0) ,(1,0,0),(2,0,0) .....,(8,5,0)\n",
    "objp = np.zeros((6*9,3),np.float32)\n",
    "objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2) #x,y coordinates\n",
    "\n",
    "# Make a list of calibration images\n",
    "\n",
    "images = glob.glob('camera_cal/calibration*.jpg')\n",
    "\n",
    "# Step through the list and search for chessboard corners\n",
    "for idx, fname in enumerate(images):\n",
    "    \n",
    "    img = cv2.imread(fname)\n",
    "    img2 = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (9,6), None)\n",
    "\n",
    "    # If found, add object points, image points\n",
    "    # If found, add object points, image points\n",
    "    if ret == True:    \n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "\n",
    "        # Draw and display the corners\n",
    "        img2 = cv2.drawChessboardCorners(img2, (9,6), corners, ret)\n",
    "\n",
    "        \n",
    "    f, (ax1,ax2) = plt.subplots(1, 2, figsize=(24,8))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(img)\n",
    "    ax1.set_title('original_Image - ' + fname[11:], fontsize=30)\n",
    "    ax2.imshow(img2)\n",
    "    ax2.set_title('corners_detected', fontsize=30)\n",
    "       \n",
    "    #You may also uncomment the following line for generate output files\n",
    "    #plt.savefig('camera_cal/ChessboardCorners/'+'ChessboardCorners_'+fname[11:])\n",
    "\n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test undistortion on an image\n",
    "img = cv2.imread('camera_cal/calibration1.jpg')\n",
    "chess_img_size = (img.shape[1], img.shape[0])\n",
    "\n",
    "# Do camera calibration given object points and image points\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, chess_img_size,None,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "images = glob.glob('camera_cal/calibration*.jpg')\n",
    "\n",
    "# Step through the list and search for chessboard corners\n",
    "for idx, fname in enumerate(images):\n",
    "    img = cv2.imread(fname)\n",
    "    dst = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    dst_image = cv2.cvtColor(dst, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Visualize undistortion\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24,5.5))\n",
    "    ax1.imshow(img)\n",
    "    ax1.set_title('Original Image- ' + fname[11:], fontsize=30)\n",
    "    ax2.imshow(dst_image)\n",
    "    ax2.set_title('Undistorted Image', fontsize=30)\n",
    "   \n",
    "    #You may also uncomment the following line for generate output files\n",
    "    #plt.savefig('camera_cal/Chessboard_Undistortion/'+'Cb_Undistortion_'+fname[11:])\n",
    "\n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying function to Undistorted the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Undistorted_Images(img,mtx,dist):\n",
    "    return cv2.undistort(img, mtx, dist, None, mtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "images = glob.glob('test_images/*.jpg')\n",
    "\n",
    "for idx, fname in enumerate(images):\n",
    "\n",
    "    img = mpimg.imread (fname)\n",
    "    undist = Undistorted_Images(img,mtx,dist)\n",
    "   \n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24,8))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(img)\n",
    "    ax1.set_title('Original image - ' + fname[12:], fontsize=30)\n",
    "    ax2.imshow(undist)\n",
    "    ax2.set_title('undistorted version', fontsize=30)\n",
    "    \n",
    "    #You may also uncomment the following line for generate output files\n",
    "    plt.savefig('output_images/Undistorted_images/'+'Undist_'+fname[12:])\n",
    "    \n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(undist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Gradient Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abs_sobel_thresh(img, orient='x',thresh = (50,150), kernel_size = 7 ):\n",
    "    \n",
    "    # Apply the following steps to img\n",
    "    #1) Convert to grayscale\n",
    "     \n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    #Applies a Gaussian Noise kernel\n",
    "    blur =  cv2.GaussianBlur(gray, (kernel_size, kernel_size), 0)\n",
    "    \n",
    "    # 2) Take the derivative in x or y given orient = 'x' or 'y'\n",
    "    if orient == 'x':\n",
    "        sobel = cv2.Sobel(blur, cv2.CV_64F, 1, 0)\n",
    "    if orient == 'y':\n",
    "        sobel = cv2.Sobel(blur, cv2.CV_64F, 0, 1)\n",
    "\n",
    "        \n",
    "    # 3) Take the absolute value of the derivative or gradient\n",
    "    abs_sobel = np.absolute(sobel)\n",
    "    \n",
    "    # 4) Scale to 8-bit (0 - 255) then convert to type = np.uint8\n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "\n",
    "    # 5) Create a mask of 1's where the scaled gradient magnitude \n",
    "            # is > thresh_min and < thresh_max\n",
    "    sbinary = np.zeros_like(scaled_sobel)\n",
    "    sbinary[(scaled_sobel >= thresh[0]) & (scaled_sobel <= thresh[1])] = 1\n",
    "\n",
    "    # 6) Return this mask as your binary_output image\n",
    "    grad_binary = sbinary\n",
    "\n",
    "    return grad_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "images = glob.glob('test_images/*.jpg')\n",
    "\n",
    "for idx, fname in enumerate(images):\n",
    "\n",
    "    img = mpimg.imread (fname)\n",
    "\n",
    "    undist = Undistorted_Images(img,mtx,dist)\n",
    "     \n",
    "    grad_binary_x = abs_sobel_thresh(undist, orient='x',thresh = (30,120), kernel_size = 5 )\n",
    "    grad_binary_y = abs_sobel_thresh(undist, orient='y',thresh = (30,120), kernel_size = 5 )\n",
    "\n",
    "    \n",
    "    f, (ax1, ax2,ax3) = plt.subplots(1, 3, figsize=(24,6))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(undist)\n",
    "    ax1.set_title('Undistorted - ' + fname[12:], fontsize=30)\n",
    "    ax2.imshow(grad_binary_x,cmap = 'gray')\n",
    "    ax2.set_title('abs_sobel_X_binary', fontsize=30)\n",
    "    ax3.imshow(grad_binary_y,cmap = 'gray')\n",
    "    ax3.set_title('abs_sobel_Y_binary', fontsize=30)\n",
    "    \n",
    "    #You may also uncomment the following line for generate output files\n",
    "    #plt.savefig('output_images/Abs_Sobel/'+'Abs_Sobel_'+fname[12:])\n",
    "    \n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mag_thresh(img,sobel_kernel=15, mag_thresh=(0, 255), blur_kernel =15):\n",
    "    \n",
    "    # Apply the following steps to img\n",
    "    # 1) Convert to grayscale and Applies a Gaussian Noise kernel\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    blur =  cv2.GaussianBlur(gray, (blur_kernel, blur_kernel), 0)\n",
    "    \n",
    "    # 2) Take the gradient in x and y separately\n",
    "    \n",
    "    sobelx = cv2.Sobel(blur, cv2.CV_64F, 1, 0,ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(blur, cv2.CV_64F, 0, 1,ksize=sobel_kernel)\n",
    "\n",
    "    # 3) Calculate the magnitude \n",
    "    \n",
    "    gradmag = np.sqrt(sobelx**2+sobely**2)\n",
    "\n",
    "    # 4) Scale to 8-bit (0 - 255) and convert to type = np.uint8\n",
    "\n",
    "    scale_factor = np.max(gradmag)/255 \n",
    "    gradmag = (gradmag/scale_factor).astype(np.uint8) \n",
    "    \n",
    "    # 5) Create a binary mask where mag thresholds are met\n",
    "    \n",
    "    binary_mask = np.zeros_like(gradmag)\n",
    "    binary_mask[(gradmag >= mag_thresh[0]) & (gradmag <= mag_thresh[1])] = 1    \n",
    "    \n",
    "    # 6) Return this mask as your binary_output image\n",
    "    \n",
    "    mag_binary = binary_mask \n",
    "    \n",
    "    return mag_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "images = glob.glob('test_images/*.jpg')\n",
    "\n",
    "for idx, fname in enumerate(images):\n",
    "\n",
    "    img = mpimg.imread (fname)\n",
    "\n",
    "    undist = Undistorted_Images(img,mtx,dist)\n",
    "    mag_binary = mag_thresh(undist,sobel_kernel=15, mag_thresh=(30, 120), blur_kernel =5)\n",
    "    \n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 8))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(undist)\n",
    "    ax1.set_title('Undistorted - '+ fname[12:], fontsize=30)\n",
    "    ax2.imshow(mag_binary,cmap = 'gray')\n",
    "    ax2.set_title('mag_thresh_binary result', fontsize=30)\n",
    "\n",
    "    #You may also uncomment the following line for generate output files    \n",
    "    #plt.savefig('output_images/magthresh/'+'magthresh_binary_'+fname[12:])\n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dir_threshold(img, sobel_kernel=3, thresh=(0, np.pi/2)):\n",
    "    \n",
    "    # Apply the following steps to img\n",
    "    # 1) Convert to grayscale\n",
    "    #gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # 2) Take the gradient in x and y separately\n",
    "    \n",
    "    sobelx = cv2.Sobel(img, cv2.CV_64F, 1, 0,ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(img, cv2.CV_64F, 0, 1,ksize=sobel_kernel)\n",
    "    \n",
    "    # 3) Take the absolute value of the x and y gradients\n",
    "\n",
    "    abs_sobelx = np.absolute(sobelx)\n",
    "    abs_sobely = np.absolute(sobely)\n",
    "    \n",
    "    # 4) Use np.arctan2(abs_sobely, abs_sobelx) to calculate the direction of the gradient \n",
    "    \n",
    "    absgraddir = np.arctan2(abs_sobely, abs_sobelx)\n",
    "    \n",
    "    # 5) Create a binary mask where direction thresholds are met\n",
    "    \n",
    "    sbinary = np.zeros_like(absgraddir)\n",
    "    sbinary[(absgraddir >= thresh[0]) & (absgraddir <= thresh[1])] = 1\n",
    "    \n",
    "    \n",
    "    # 6) Return this mask as your binary_output image\n",
    "    #binary_output = np.copy(img) # Remove this line\n",
    "\n",
    "    dir_binary = sbinary\n",
    "    \n",
    "    return dir_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "images = glob.glob('test_images/*.jpg')\n",
    "\n",
    "for idx, fname in enumerate(images):\n",
    "\n",
    "    img = mpimg.imread (fname)\n",
    "\n",
    "    undist = Undistorted_Images(img,mtx,dist)\n",
    "    dir_binary = dir_threshold(undist, sobel_kernel=11, thresh=(0.6, 1.2))\n",
    "    \n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 8))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(undist)\n",
    "    ax1.set_title('Undistorted - '+fname[12:], fontsize=30)\n",
    "    ax2.imshow(dir_binary,cmap = 'gray')\n",
    "    ax2.set_title('dir_threshold_binary', fontsize=30)\n",
    "\n",
    "    #You may also uncomment the following line for generate output files    \n",
    "    #plt.savefig('output_images/dir_threshold/'+'dir_threshold_'+fname[12:])\n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Color Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_binary(img,channel,thresh =(200,255)):\n",
    "\n",
    "    \n",
    "    if channel == 'r':\n",
    "        channel = img[:,:,0]\n",
    "    if channel == 'g':\n",
    "        channel = img[:,:,1]  \n",
    "    if channel == 'b':\n",
    "        channel = img[:,:,2]  \n",
    "    # 2) Apply a threshold to the S channel\n",
    "    \n",
    "    binary = np.zeros_like(channel)\n",
    "    binary[(channel > thresh[0]) & (channel <= thresh[1])] = 1\n",
    "\n",
    "    \n",
    "    # 3) Return a binary image of threshold result\n",
    "    \n",
    "    #binary_output = np.copy(img) # placeholder line\n",
    "    rgb_binary =  binary\n",
    "    \n",
    "    return rgb_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = glob.glob('test_images/*.jpg')\n",
    "\n",
    "rgb_thresh =(200,255)\n",
    "\n",
    "for idx, fname in enumerate(images):\n",
    "\n",
    "    img = mpimg.imread (fname)\n",
    "\n",
    "    undist = Undistorted_Images(img,mtx,dist)\n",
    "    rgb_binary_r = rgb_binary(undist,'r',rgb_thresh)\n",
    "    rgb_binary_g = rgb_binary(undist,'g',rgb_thresh)\n",
    "    rgb_binary_b = rgb_binary(undist,'b',rgb_thresh)\n",
    "    \n",
    "    \n",
    "    f, (ax1, ax2,ax3,ax4) = plt.subplots(1, 4, figsize=(24, 4))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(undist)\n",
    "    ax1.set_title('Undistorted - '+fname[12:], fontsize=20)\n",
    "    ax2.imshow(rgb_binary_r,cmap = 'gray')\n",
    "    ax2.set_title('R channel_binary', fontsize=20)\n",
    "    ax3.imshow(rgb_binary_g,cmap = 'gray')\n",
    "    ax3.set_title('G channel_binary', fontsize=20)\n",
    "    ax4.imshow(rgb_binary_b,cmap = 'gray')\n",
    "    ax4.set_title('B channel_binary', fontsize=20)\n",
    "\n",
    "    #You may also uncomment the following line for generate output files\n",
    "    #plt.savefig('output_images/rgb_binary/'+'rgb_binary_'+fname[12:])\n",
    "    \n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hls_binary(img,channel,thresh =( 0,255)):\n",
    "    # 1) Convert to HLS color space\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    if channel == 'h':\n",
    "        channel = hls[:,:,0]\n",
    "    if channel == 'l':\n",
    "        channel = hls[:,:,1]  \n",
    "    if channel == 's':\n",
    "        channel = hls[:,:,2]  \n",
    "    # 2) Apply a threshold to the S channel\n",
    "    \n",
    "    binary = np.zeros_like(channel)\n",
    "    binary[(channel >= thresh[0]) & (channel <= thresh[1])] = 1\n",
    "    \n",
    "    # 3) Return a binary image of threshold result\n",
    "    \n",
    "    #binary_output = np.copy(img) # placeholder line\n",
    "    hls_binary =  binary\n",
    "    \n",
    "    return hls_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "images = glob.glob('test_images/*.jpg')\n",
    "\n",
    "hls_thresh =(180,255)\n",
    "\n",
    "for idx, fname in enumerate(images):\n",
    "\n",
    "    img = mpimg.imread (fname)\n",
    "\n",
    "    undist = Undistorted_Images(img,mtx,dist)\n",
    "    hls_binary_h = hls_binary(undist,'h',hls_thresh)\n",
    "    hls_binary_l = hls_binary(undist,'l',hls_thresh)\n",
    "    hls_binary_s = hls_binary(undist,'s',hls_thresh)\n",
    "    \n",
    "    \n",
    "    f, (ax1, ax2,ax3,ax4) = plt.subplots(1, 4, figsize=(24, 4))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(undist)\n",
    "    ax1.set_title('Undistorted - '+fname[12:], fontsize=20)\n",
    "    ax2.imshow(hls_binary_h,cmap = 'gray')\n",
    "    ax2.set_title('h channel_binary', fontsize=20)\n",
    "    ax3.imshow(hls_binary_l,cmap = 'gray')\n",
    "    ax3.set_title('l channel_binary', fontsize=20)\n",
    "    ax4.imshow(hls_binary_s,cmap = 'gray')\n",
    "    ax4.set_title('s channel_binary', fontsize=20)\n",
    "\n",
    "    #You may also uncomment the following line for generate output files    \n",
    "    #plt.savefig('output_images/hls_binary/'+'hls_binary_'+fname[12:])\n",
    "    \n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining gradient and color thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_and_gradient(img,sx_thresh,rgb_thresh,hls_thresh):\n",
    "    \n",
    "    gradx = abs_sobel_thresh(img,orient='x', thresh = (sx_thresh[0], sx_thresh[1]),kernel_size = 5)\n",
    "    r_binary = rgb_binary(img,'r', thresh = (rgb_thresh[0],rgb_thresh[1]))\n",
    "    s_binary = hls_binary(img,'s', thresh = (hls_thresh[0],hls_thresh[1]))\n",
    "    \n",
    "    # Stack each channel\n",
    "    #color_binary = np.dstack(( np.zeros_like(gradx ),gradx ,s_binary  )) * 255\n",
    "    \n",
    "    combined_binary = np.zeros_like(gradx)\n",
    "    combined_binary[(r_binary == 1) |(s_binary == 1) & (gradx == 1)] = 1\n",
    "  \n",
    "    return gradx,r_binary,s_binary,combined_binary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = glob.glob('test_images/*.jpg')\n",
    "\n",
    "for idx, fname in enumerate(images):\n",
    "\n",
    "    img = mpimg.imread (fname)\n",
    "\n",
    "    undist = Undistorted_Images(img,mtx,dist)\n",
    "\n",
    "    gradx,r_binary,s_binary,combined_binary = color_and_gradient(undist,sx_thresh = (30,120),rgb_thresh = (220,255),hls_thresh = (180,255))\n",
    "    \n",
    "    f, (ax1, ax2,ax3,ax4) = plt.subplots(1, 4, figsize=(24, 4))\n",
    "    f.tight_layout()\n",
    "\n",
    "    ax1.imshow(combined_binary,cmap = 'gray')\n",
    "    ax1.set_title('combined - '+fname[12:], fontsize=20)        \n",
    "    ax2.imshow(r_binary,cmap = 'gray')\n",
    "    ax2.set_title('R channel', fontsize=20)  \n",
    "    ax3.imshow(gradx,cmap = 'gray')\n",
    "    ax3.set_title('abs_sobel_X_binary', fontsize=20)\n",
    "    ax4.imshow(s_binary,cmap = 'gray')\n",
    "    ax4.set_title('s channel_binary', fontsize=20)\n",
    "\n",
    "    #You may also uncomment the following line for generate output files    \n",
    "    plt.savefig('output_images/combined_binary/'+'combined_binary_'+fname[12:])\n",
    "    \n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating functions to Mask the lanes lines image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_mask (img):\n",
    "\n",
    "    #defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)   \n",
    "    \n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "    \n",
    "    imshape = img.shape\n",
    "    vertices = np.array([[(100,imshape[0]),(550,450), (imshape[1]-520, 450), (imshape[1]-60,imshape[0])]], dtype=np.int32)        \n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    \n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "images = glob.glob('test_images/straight_lines*.jpg')\n",
    "\n",
    "for idx, fname in enumerate(images):\n",
    "\n",
    "    img = mpimg.imread (fname)\n",
    "\n",
    "    undist = Undistorted_Images(img,mtx,dist)\n",
    "\n",
    "    marked_image = apply_mask (undist)\n",
    "    \n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 8))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(undist)\n",
    "    ax1.set_title('Undistorted - '+fname[12:], fontsize=30)\n",
    "    ax2.imshow(marked_image,cmap = 'gray')\n",
    "    ax2.set_title('Masked_image', fontsize=30)\n",
    "\n",
    "    #You may also uncomment the following line for generate output files    \n",
    "    #plt.savefig('output_images/masked/'+'masked_'+fname[12:])\n",
    "    \n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying extended lines on images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_Extended_lines(img, lines, color=[255, 0, 0], thickness=15):\n",
    "\n",
    "    #The try statement was created due video test results. In some cases the video was not generated,\n",
    "    #because some point was not identified and the algorithm could not calculate the average due to occur\n",
    "    #the division by zero. ( avg_x1 , .... , avg_y4).\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        # generating lists with the coordinate value for each point.\n",
    "        imshape = img.shape\n",
    "        y_lower = imshape[0]\n",
    "        x1l = []\n",
    "        y1l = []\n",
    "        x2l = []\n",
    "        y2l = [] \n",
    "        x3l = []\n",
    "        y3l = []\n",
    "        x4l = []\n",
    "        y4l = [] \n",
    "        for line in lines:       \n",
    "            for x1,y1,x2,y2 in line:\n",
    "                if((y2-y1)/(x2-x1))<0:\n",
    "                    x1l.append(x1)\n",
    "                    y1l.append(y1)\n",
    "                    x2l.append(x2)\n",
    "                    y2l.append(y2)\n",
    "                else:\n",
    "                    x3l.append(x1)\n",
    "                    y3l.append(y1)\n",
    "                    x4l.append(x2)\n",
    "                    y4l.append(y2)                \n",
    "\n",
    "        # Calculate the average for eache coordinate - 8 coordinates / 4 points / 2 lines.\n",
    "                    \n",
    "        avg_x1 = int(sum(x1l)/len(x1l))\n",
    "        avg_y1 = int(sum(y1l)/len(y1l))\n",
    "        avg_x2 = int(sum(x2l)/len(x2l))                \n",
    "        avg_y2 = int(sum(y2l)/len(y2l))                \n",
    "        avg_x3 = int(sum(x3l)/len(x3l))\n",
    "        avg_y3 = int(sum(y3l)/len(y3l))\n",
    "        avg_x4 = int(sum(x4l)/len(x4l))                \n",
    "        avg_y4 = int(sum(y4l)/len(y4l))\n",
    "\n",
    "\n",
    "        #Applying Analytic geometry concept to accomplish the goals\n",
    "        #The \"General Form\" of the equation of a straight line Ax + By + C = 0\n",
    "        \n",
    "        a1 = avg_y1-avg_y2\n",
    "        b1 = avg_x2-avg_x1\n",
    "        c1 = (avg_x1*avg_y2)-(avg_y1*avg_x2)\n",
    "\n",
    "        a2 = avg_y3-avg_y4\n",
    "        b2 = avg_x4-avg_x3\n",
    "        c2 = (avg_x3*avg_y4)-(avg_y3*avg_x4)   \n",
    "\n",
    "\n",
    "        #For the upper point will be considered Y coordinate at the limite of the masked imag = 450 +20 :\n",
    "        \n",
    "        y_upper = 500\n",
    "        \n",
    "        x_upper_line_left = int((-b1*y_upper-c1)/a1)\n",
    "        x_upper_line_right = int((-b2*y_upper-c2)/a2)\n",
    "        \n",
    "\n",
    "        #calculating the Xpoint coordinate for lower point from the lines.\n",
    "        # The Y coordinate is equal to the image size. \"y_lower = imshape[1]\"\n",
    "\n",
    "        x_lower_line_left = int((-b1*y_lower-c1)/a1)\n",
    "        x_lower_line_right = int((-b2*y_lower-c2)/a2)\n",
    "\n",
    "        p1 = [x_lower_line_left,y_lower]\n",
    "        p2 = [x_upper_line_left,y_upper]        \n",
    "        p3 = [x_upper_line_right,y_upper]        \n",
    "        p4 = [x_lower_line_right,y_lower]        \n",
    "        \n",
    "        # generating extended lines (left and Right)\n",
    "        cv2.line(img,(p1[0],p1[1]),(p2[0],p2[1]), color, thickness)\n",
    "        cv2.line(img,(p3[0],p3[1]),(p4[0],p4[1]), color, thickness)\n",
    "                       \n",
    "    except:\n",
    "        pass \n",
    "    \n",
    "    \n",
    "def hough_Extended_lines(img, rho, theta, threshold, min_line_len, max_line_gap):\n",
    "\n",
    "    lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "    line_img = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\n",
    "    draw_Extended_lines(line_img, lines)\n",
    "    return line_img \n",
    "\n",
    "def weighted_img(img, initial_img, α=0.8, β=1., γ=0.):\n",
    "\n",
    "    return cv2.addWeighted(initial_img, α, img, β, γ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_extended_lines(img):\n",
    "    undist = Undistorted_Images(img,mtx,dist)\n",
    "    gradx,r_binary,s_binary,combined_binary = color_and_gradient(undist,sx_thresh = (30,120),rgb_thresh = (220,255),hls_thresh = (180,255))\n",
    "\n",
    "    masked_image = apply_mask (combined_binary)\n",
    "\n",
    "    rho = 1 # distance resolution in pixels of the Hough grid\n",
    "    theta = np.pi/180 # angular resolution in radians of the Hough grid\n",
    "    threshold = 15  # minimum number of votes (intersections in Hough grid cell)\n",
    "    min_line_len = 20 #minimum number of pixels making up a line\n",
    "    max_line_gap = 300  # maximum gap in pixels between connectable line segments\n",
    "\n",
    "    extended_lines_edges = hough_Extended_lines(masked_image, rho, theta, threshold, min_line_len, max_line_gap)\n",
    "    extended_weighted_img = weighted_img(extended_lines_edges, undist, α=0.3, β=1, γ=1)\n",
    "    \n",
    "    return extended_weighted_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "images = glob.glob('test_images/straight_lines*.jpg')\n",
    "\n",
    "for idx, fname in enumerate(images):\n",
    "\n",
    "    img = mpimg.imread (fname)\n",
    "\n",
    "    undist = Undistorted_Images(img,mtx,dist)\n",
    "\n",
    "    lines = draw_extended_lines (undist)\n",
    "    \n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 8))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(undist)\n",
    "    ax1.set_title('Undistorted - '+fname[12:], fontsize=30)\n",
    "    ax2.imshow(lines,cmap = 'gray')\n",
    "    ax2.set_title('Lines added', fontsize=30)\n",
    "\n",
    "    #You may also uncomment the following line for generate output files    \n",
    "    #plt.savefig('output_images/get_coordinate_lines/'+'get_coordinate_lines_'+fname[12:])    \n",
    "    \n",
    "#get_coordinate_lines    \n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting coordinates to support warp function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to construct a reliable matrix to warp the images, it will be considered the images straight_lines 1 and 2 , because the lines generated programmatically, show good results. As second step, it will be calculated the tangent ($\\Delta$y/$\\Delta$x) for the left line and right line\n",
    "\n",
    "To ensure that will be considered the whole line lenght , from the 6 images available will be considered the \"x\" coordinates minimun and  maximum in the lower region of the pictures  and it will be applied the tangent angle for both lines inverting the direction on each case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It will be created a function simlar from the function that have draw the lines,\n",
    "# but the functin will return the coordinates for the 4 points .\n",
    "\n",
    "\n",
    "def get_coordinates(line_img,lines):\n",
    "\n",
    "    #The try statement was created due video test results. In some cases the video was not generated,\n",
    "    #because some point was not identified and the algorithm could not calculate the average due to occur\n",
    "    #the division by zero. ( avg_x1 , .... , avg_y4).\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        # generating lists with the coordinate value for each point.\n",
    "        imshape = line_img.shape\n",
    "        y_lower = imshape[0]\n",
    "        x1l = []\n",
    "        y1l = []\n",
    "        x2l = []\n",
    "        y2l = [] \n",
    "        x3l = []\n",
    "        y3l = []\n",
    "        x4l = []\n",
    "        y4l = [] \n",
    "        for line in lines:       \n",
    "            for x1,y1,x2,y2 in line:\n",
    "                if((y2-y1)/(x2-x1))<0:\n",
    "                    x1l.append(x1)\n",
    "                    y1l.append(y1)\n",
    "                    x2l.append(x2)\n",
    "                    y2l.append(y2)\n",
    "                else:\n",
    "                    x3l.append(x1)\n",
    "                    y3l.append(y1)\n",
    "                    x4l.append(x2)\n",
    "                    y4l.append(y2)                \n",
    "\n",
    "        # Calculate the average for eache coordinate - 8 coordinates / 4 points / 2 lines.\n",
    "                    \n",
    "        avg_x1 = int(sum(x1l)/len(x1l))\n",
    "        avg_y1 = int(sum(y1l)/len(y1l))\n",
    "        avg_x2 = int(sum(x2l)/len(x2l))                \n",
    "        avg_y2 = int(sum(y2l)/len(y2l))                \n",
    "        avg_x3 = int(sum(x3l)/len(x3l))\n",
    "        avg_y3 = int(sum(y3l)/len(y3l))\n",
    "        avg_x4 = int(sum(x4l)/len(x4l))                \n",
    "        avg_y4 = int(sum(y4l)/len(y4l))\n",
    "\n",
    "\n",
    "        #Applying Analytic geometry concept to accomplish the goals\n",
    "        #The \"General Form\" of the equation of a straight line Ax + By + C = 0\n",
    "        \n",
    "        a1 = avg_y1-avg_y2\n",
    "        b1 = avg_x2-avg_x1\n",
    "        c1 = (avg_x1*avg_y2)-(avg_y1*avg_x2)\n",
    "\n",
    "        a2 = avg_y3-avg_y4\n",
    "        b2 = avg_x4-avg_x3\n",
    "        c2 = (avg_x3*avg_y4)-(avg_y3*avg_x4)   \n",
    "\n",
    "\n",
    "        #For the upper point will be considered Y coordinate at the limite of the masked imag = 450 +20 :\n",
    "        \n",
    "        y_upper = 450\n",
    "        \n",
    "        x_upper_line_left = int((-b1*y_upper-c1)/a1)\n",
    "        x_upper_line_right = int((-b2*y_upper-c2)/a2)\n",
    "        \n",
    "\n",
    "        #calculating the Xpoint coordinate for lower point from the lines.\n",
    "        # The Y coordinate is equal to the image size. \"y_lower = imshape[1]\"\n",
    "\n",
    "        x_lower_line_left = int((-b1*y_lower-c1)/a1)\n",
    "        x_lower_line_right = int((-b2*y_lower-c2)/a2)\n",
    "\n",
    "        p1 = [x_lower_line_left,y_lower]\n",
    "        p2 = [x_upper_line_left,y_upper]        \n",
    "        p3 = [imshape[1]-x_upper_line_left,y_upper]        \n",
    "        p4 = [imshape[1]-x_lower_line_left,y_lower]        \n",
    "        \n",
    "        return p1,p2,p3,p4\n",
    "    \n",
    "    except:\n",
    "        pass \n",
    "    \n",
    "def hough_Extended_lines_2 (img, rho, theta, threshold, min_line_len, max_line_gap):\n",
    "\n",
    "    lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "    line_img = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\n",
    "    p1,p2,p3,p4 = get_coordinates(line_img, lines)\n",
    "    \n",
    "    return p1,p2,p3,p4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Getting the 4 points coordinates for all pictures available.\n",
    "\n",
    "def getting_4_points_coordinates (img):\n",
    "    undist = Undistorted_Images(img,mtx,dist)\n",
    "    gradx,r_binary,s_binary,combined_binary = color_and_gradient(undist,sx_thresh = (50,150),rgb_thresh = (220,255),hls_thresh = (180,255))\n",
    "\n",
    "    masked_image = apply_mask (combined_binary)\n",
    "\n",
    "    rho = 1 # distance resolution in pixels of the Hough grid\n",
    "    theta = np.pi/180 # angular resolution in radians of the Hough grid\n",
    "    threshold = 15  # minimum number of votes (intersections in Hough grid cell)\n",
    "    min_line_len = 20 #minimum number of pixels making up a line\n",
    "    max_line_gap = 300  # maximum gap in pixels between connectable line segments\n",
    "\n",
    "    p1,p2,p3,p4 = hough_Extended_lines_2(masked_image, rho, theta, threshold, min_line_len, max_line_gap)\n",
    "\n",
    "    m_points = [p1,p2,p3,p4]\n",
    "    \n",
    "    return m_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating the average for the tangente for the left and right lines for the files with straight_lines.\n",
    "\n",
    "straight_lines_files = ['straight_lines1.jpg','straight_lines2.jpg']\n",
    "\n",
    "tan_value =[]\n",
    "\n",
    "for i in straight_lines_files:\n",
    "\n",
    "    img = mpimg.imread ('test_images/'+i)\n",
    "    m_points = getting_4_points_coordinates (img)\n",
    "\n",
    "    tan_line_left = (m_points[0][1]-m_points[1][1])/(m_points[1][0]-m_points[0][0])\n",
    "    tan_value.append(tan_line_left)\n",
    "    tan_line_right = (m_points[3][1]-m_points[2][1])/(m_points[3][0]-m_points[2][0])\n",
    "    tan_value.append(tan_line_right)\n",
    "\n",
    "avg_tan = sum(tan_value)/len(tan_value)\n",
    "\n",
    "avg_tan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In order to ensure the lane lines, It Will be checked the minimum and maximum X coordinate available\n",
    "#in a set of images.\n",
    "\n",
    "\n",
    "images = glob.glob('test_images/*.jpg')\n",
    "\n",
    "min_max_X_lower_coordinates = [1000,0]\n",
    "\n",
    "for idx, fname in enumerate(images):\n",
    "\n",
    "    img = mpimg.imread (fname)\n",
    "    m_points = getting_4_points_coordinates (img)\n",
    "    \n",
    "    if m_points[0][0] < min_max_X_lower_coordinates[0]:\n",
    "        min_max_X_lower_coordinates[0] = m_points[0][0]\n",
    "    if m_points[3][0]> min_max_X_lower_coordinates[1]:\n",
    "        min_max_X_lower_coordinates[1] = m_points[3][0]\n",
    "        \n",
    "min_max_X_lower_coordinates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking if the reference line point must be from left , right line or any line.\n",
    "    \n",
    "img = mpimg.imread ('test_images/test1.jpg')\n",
    "imshape = img.shape\n",
    "    \n",
    "    \n",
    "if (imshape[1]- min_max_X_lower_coordinates[1] ) == min_max_X_lower_coordinates [0]:\n",
    "    print (\"any line could be used as reference\")    \n",
    "\n",
    "elif (imshape[1] - min_max_X_lower_coordinates[1] ) > min_max_X_lower_coordinates [0]:\n",
    "    print (\"use right lower point (P4x) as reference\")\n",
    "    \n",
    "else:\n",
    "    print (\"use left lower point (P1x) as reference\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the avg_tan previously calculated for the min and max lower \"X\" coordinates (p1,p2),\n",
    "# and fixing the \"Y\" coordinate =450 , it will be calculated the X cordinate for the upper points (p2 , p3).\n",
    "\n",
    "#The new matrix with this 4 new points it will considered as the source information for the warped function.\n",
    "\n",
    "img = mpimg.imread ('test_images/straight_lines1.jpg')\n",
    "\n",
    "imshape = img.shape\n",
    "\n",
    "y_upper = 460\n",
    "y_lower = imshape[0]\n",
    "\n",
    "\n",
    "# In order to keep a symmetry, the P1 \"X\" position will be adjusted considering the P4 \"X\"value.\n",
    "\n",
    "p1_x = (min_max_X_lower_coordinates [0])\n",
    "\n",
    "p4_x = (min_max_X_lower_coordinates [1])\n",
    "\n",
    "p2_x = (((y_lower - y_upper) / avg_tan)+ p1_x)\n",
    "\n",
    "p3_x = (p4_x - ((y_lower - y_upper) / avg_tan))\n",
    "\n",
    "np1,np2,np3,np4 = [p1_x,y_lower],[p2_x,y_upper ],[p3_x,y_upper ],[p4_x,y_lower]\n",
    "\n",
    "np1,np2,np3,np4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the source matrix (src) and destination\n",
    "\n",
    "#the coefficient applied was created to tuning the warped image\n",
    "\n",
    "coef = 55\n",
    "    \n",
    "np2[0] = np2[0]+coef\n",
    "np3[0] = np3[0]-coef\n",
    "\n",
    "src = np.float32([np1,np2,np3,np4])\n",
    "\n",
    "offset= 220\n",
    "height, width = undist.shape[0], undist.shape[1]\n",
    "dst = np.float32([[offset,height],[offset,0],[width-offset,0],[width-offset,height]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining function to warp images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining Matrixs M and Minv.\n",
    "\n",
    "M = cv2.getPerspectiveTransform(src,dst)\n",
    "Minv = cv2.getPerspectiveTransform(dst,src)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warp_images (img):\n",
    "    \n",
    "    undist = Undistorted_Images(img,mtx,dist)\n",
    "    warped = cv2.warpPerspective(undist, M ,(imshape[1], imshape[0]))\n",
    "\n",
    "    return undist,warped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "images = glob.glob('test_images/*.jpg')\n",
    "\n",
    "for idx, fname in enumerate(images):\n",
    "\n",
    "    img = mpimg.imread (fname)\n",
    "    undist,warped = warp_images (img)\n",
    "    gradx,r_binary,s_binary,combined_binary = color_and_gradient(warped,sx_thresh = (30,120),rgb_thresh = (220,255),hls_thresh = (180,255))\n",
    "    \n",
    "    f, (ax1, ax2,ax3) = plt.subplots(1,3, figsize=(24, 5.5))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(undist)\n",
    "    ax1.set_title('Undistorted - '+str(fname[12:]), fontsize=25)\n",
    "    ax2.imshow(warped,cmap = 'gray')\n",
    "    ax2.set_title('warped ', fontsize=25)\n",
    "    ax3.imshow(combined_binary,cmap = 'gray')\n",
    "    ax3.set_title('warped Binary  ', fontsize=25)\n",
    "\n",
    "    #You may also uncomment the following line for generate output files    \n",
    "    #plt.savefig('output_images/warp_images/'+'warped_'+fname[12:])    \n",
    "    \n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Pipeline to create warped binary image and plot a histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pipeline_warped_binary (img):\n",
    "\n",
    "    undist,warped = warp_images (img)\n",
    "    gradx,r_binary,s_binary,combined_binary = color_and_gradient(warped,sx_thresh = (30,120),rgb_thresh = (220,255),hls_thresh = (180,255))\n",
    "    return undist,combined_binary\n",
    "\n",
    "def hist(img):\n",
    "    \n",
    "    #imshape = img.shape\n",
    "    \n",
    "    img =  (img - np.min(img))/np.ptp(img)\n",
    "    \n",
    "    bottom_half =  img[img.shape[0]//2:,:]\n",
    "    histogram = np.sum(bottom_half, axis=0)\n",
    "    \n",
    "    return histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "images = glob.glob('test_images/*.jpg')\n",
    "\n",
    "for idx, fname in enumerate(images):\n",
    "\n",
    "    img = mpimg.imread (fname)\n",
    "    undist,binary_warped = Pipeline_warped_binary(img)\n",
    "    \n",
    "    histogram = np.sum(binary_warped[binary_warped.shape[0]//2:,:], axis=0)\n",
    "\n",
    "    \n",
    "    f, (ax1, ax2,ax3) = plt.subplots(1,3, figsize=(22, 5))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(undist)\n",
    "    ax1.set_title('Undistorted -'+ str(fname[12:]), fontsize=20)\n",
    "    ax2.imshow(binary_warped,cmap = 'gray')\n",
    "    ax2.set_title('warped_binary', fontsize=20)\n",
    "    ax3.plot(histogram)\n",
    "\n",
    "    #You may also uncomment the following line for generate output files\n",
    "    #plt.savefig('output_images/histogram/'+'histogram_'+fname[12:])     \n",
    "    \n",
    "    plt.subplots_adjust(left=0., right=1, top=1.5, bottom=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying lane curves on warped binary images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_lane_pixels(binary_warped):\n",
    "    # Take a histogram of the bottom half of the image\n",
    "    histogram = np.sum(binary_warped[binary_warped.shape[0]//2:,:], axis=0)\n",
    "    # Create an output image to draw on and visualize the result\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]//2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "    # HYPERPARAMETERS\n",
    "    # Choose the number of sliding windows\n",
    "    nwindows = 25\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 100\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 50\n",
    "\n",
    "    # Set height of windows - based on nwindows above and image shape\n",
    "    window_height = np.int(binary_warped.shape[0]//nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Current positions to be updated later for each window in nwindows\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
    "        win_y_high = binary_warped.shape[0] - window*window_height\n",
    "        ### TO-DO: Find the four below boundaries of the window ###\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        \n",
    "        # Draw the windows on the visualization image\n",
    "        cv2.rectangle(out_img,(win_xleft_low,win_y_low),\n",
    "        (win_xleft_high,win_y_high),(0,255,0), 2) \n",
    "        cv2.rectangle(out_img,(win_xright_low,win_y_low),\n",
    "        (win_xright_high,win_y_high),(0,255,0), 2) \n",
    "        \n",
    "        ### TO-DO: Identify the nonzero pixels in x and y within the window ###\n",
    "        good_left_inds =  ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xleft_low) &  (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xright_low) &  (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        \n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        \n",
    "        ### TO-DO: If you found > minpix pixels, recenter next window ###\n",
    "        ### (`right` or `leftx_current`) on their mean position ###\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))        \n",
    "\n",
    "        #pass # Remove this when you add your function\n",
    "\n",
    "    # Concatenate the arrays of indices (previously was a list of lists of pixels)\n",
    "    try:\n",
    "        left_lane_inds = np.concatenate(left_lane_inds)\n",
    "        right_lane_inds = np.concatenate(right_lane_inds)\n",
    "    except ValueError:\n",
    "        # Avoids an error if the above is not implemented fully\n",
    "        pass\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    return leftx, lefty, rightx, righty, out_img\n",
    "\n",
    "\n",
    "def fit_polynomial(binary_warped):\n",
    "    # Find our lane pixels first\n",
    "    leftx, lefty, rightx, righty, out_img = find_lane_pixels(binary_warped)\n",
    "\n",
    "    ### TO-DO: Fit a second order polynomial to each using `np.polyfit` ###\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "    try:\n",
    "        left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "        right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    except TypeError:\n",
    "        # Avoids an error if `left` and `right_fit` are still none or incorrect\n",
    "        print('The function failed to fit a line!')\n",
    "        left_fitx = 1*ploty**2 + 1*ploty\n",
    "        right_fitx = 1*ploty**2 + 1*ploty\n",
    "\n",
    "    ## Visualization ##\n",
    "    # Colors in the left and right lane regions\n",
    "    out_img[lefty, leftx] = [255, 0, 0]\n",
    "    out_img[righty, rightx] = [0, 0, 255]\n",
    "\n",
    "    # Plots the left and right polynomials on the lane lines\n",
    "    #plt.plot(left_fitx, ploty, color='yellow')\n",
    "    #plt.plot(right_fitx, ploty, color='yellow')\n",
    "\n",
    "    return  left_fit,right_fit,ploty , left_fitx , right_fitx, out_img\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_lines_warped(binary_warped ,ploty , left_fitx , right_fitx,out_img):\n",
    "    \n",
    "    warp_zero = np.zeros_like(binary_warped).astype(np.uint8)\n",
    "    #color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "    \n",
    "    color_warp = out_img\n",
    "\n",
    "    \n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "    \n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "    #cv2.fillPoly(color_warp, np.int_([pts_right]), (0,255, 0))\n",
    "\n",
    "    \n",
    "    result = color_warp\n",
    "\n",
    "  \n",
    "    \n",
    "    return result     \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_lines_warped(binary_warped ,ploty , left_fitx , right_fitx,out_img):\n",
    "\n",
    "    margin = 100  \n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "    window_img = np.zeros_like(out_img)\n",
    "\n",
    "    # Generate a polygon to illustrate the search window area\n",
    "    # And recast the x and y points into usable format for cv2.fillPoly()\n",
    "    left_line_window1 = np.array([np.transpose(np.vstack([left_fitx-margin, ploty]))])\n",
    "    left_line_window2 = np.array([np.flipud(np.transpose(np.vstack([left_fitx+margin, \n",
    "                              ploty])))])\n",
    "    left_line_pts = np.hstack((left_line_window1, left_line_window2))\n",
    "    right_line_window1 = np.array([np.transpose(np.vstack([right_fitx-margin, ploty]))])\n",
    "    right_line_window2 = np.array([np.flipud(np.transpose(np.vstack([right_fitx+margin, \n",
    "                              ploty])))])\n",
    "    right_line_pts = np.hstack((right_line_window1, right_line_window2))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(window_img, np.int_([left_line_pts]), (0,255, 0))\n",
    "    cv2.fillPoly(window_img, np.int_([right_line_pts]), (0,255, 0))\n",
    "    \n",
    "    result = cv2.addWeighted(out_img, 1, window_img, 0.3, 0)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check values left_fitx , right_fitx to validate fit_polynomial function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to support the Advanced lane Finding code  to be appled on videos, it will be created the constantes\n",
    "#sl_left_fit and sl_right_fit to use as reference. The image will be straight_lines1.jpg.\n",
    "\n",
    "img = mpimg.imread ('test_images/straight_lines1.jpg')\n",
    "undist,binary_warped = Pipeline_warped_binary (img)\n",
    "sl_left_fit,sl_right_fit, ploty , left_fitx , right_fitx, out_img = fit_polynomial(binary_warped)\n",
    "\n",
    "\n",
    "print (sl_left_fit)\n",
    "print (sl_right_fit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "images = glob.glob('test_images/*.jpg')\n",
    "\n",
    "for idx, fname in enumerate(images):\n",
    "\n",
    "    img = mpimg.imread (fname)\n",
    "    undist,binary_warped = Pipeline_warped_binary (img)\n",
    "    left_fit,right_fit,ploty , left_fitx , right_fitx, out_img = fit_polynomial(binary_warped)\n",
    "    result = draw_lines_warped(binary_warped ,ploty , left_fitx , right_fitx,out_img)\n",
    "    \n",
    "    f, (ax1, ax2,ax3) = plt.subplots(1,3, figsize=(24, 5.5))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(undist)\n",
    "    ax1.set_title('Undistorted -'+ str(fname[12:]), fontsize=30)\n",
    "    ax2.imshow(binary_warped,cmap = 'gray')\n",
    "    ax2.set_title('binary_warped', fontsize=30)\n",
    "    ax3.imshow(result)\n",
    "    ax3.set_title('Polynomial-Warped', fontsize=30)\n",
    "\n",
    "    #You may also uncomment the following line for generate output files    \n",
    "    #plt.savefig('output_images/polynomial/'+'polynomial_'+fname[12:])    \n",
    "    \n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## adding curves on original image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "\n",
    "\n",
    "def draw_lines(warped ,ploty , left_fitx , right_fitx):\n",
    "    \n",
    "    # Create an image to draw the lines on\n",
    "    warp_zero = np.zeros_like(warped).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(color_warp, Minv, (warped.shape[1], warped.shape[0])) \n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(undist, 1, newwarp, 0.3, 0)\n",
    "\n",
    "    return result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "images = glob.glob('test_images/*.jpg')\n",
    "\n",
    "for idx, fname in enumerate(images):\n",
    "\n",
    "    img = mpimg.imread (fname)\n",
    "    undist,binary_warped = Pipeline_warped_binary (img)\n",
    "    left_fit,right_fit,ploty , left_fitx , right_fitx,out_img = fit_polynomial(binary_warped)\n",
    "    result = draw_lines(binary_warped ,ploty , left_fitx , right_fitx)\n",
    "    \n",
    "    f, (ax1, ax2) = plt.subplots(1,2, figsize=(24, 8))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(img)\n",
    "    ax1.set_title('Original image -'+ str(fname[12:]), fontsize=30)\n",
    "    ax2.imshow(result)\n",
    "    ax2.set_title('detected lane', fontsize=30)\n",
    "    \n",
    "    #You may also uncomment the following line for generate output files    \n",
    "    #plt.savefig('output_images/warp_back/'+'warp_back_'+fname[12:])\n",
    "    \n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining functions to calculate Vehicle turn radius and the offset position on lane line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to accurate the conversion from pixels to meters , It will be used the left_fitx[719] and right_fitx [719]\n",
    "#generated from the image straight_lines1.jpg the diference between this 2 values is the lane width in pixels.\n",
    "\n",
    "img = mpimg.imread ('test_images/straight_lines1.jpg')\n",
    "undist,binary_warped = Pipeline_warped_binary (img)\n",
    "left_fit,right_fit, ploty , left_fitx , right_fitx, out_img = fit_polynomial(binary_warped)\n",
    "\n",
    "\n",
    "lane_line_width_pixels = right_fitx[719]- left_fitx [719]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_curvature_real():\n",
    "    '''\n",
    "    Calculates the curvature of polynomial functions in meters.\n",
    "    '''\n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "    xm_per_pix = float(3.7/lane_line_width_pixels)\n",
    "    ym_per_pix = float(30/(720)) # meters per pixel in y dimension\n",
    "    \n",
    "    # Start by generating our fake example data\n",
    "    # Make sure to feed in your real data instead in your project!\n",
    "    left_fit,right_fit,ploty ,left_fitx , right_fitx,out_img = fit_polynomial(binary_warped)\n",
    "    \n",
    "    # Define y-value where we want radius of curvature\n",
    "    # We'll choose the maximum y-value, corresponding to the bottom of the image\n",
    "    \n",
    "    left_fitx = left_fitx[::-1]  # Reverse to match top-to-bottom in y\n",
    "    right_fitx = right_fitx[::-1]  # Reverse to match top-to-bottom in y\n",
    "    \n",
    "    \n",
    "    left_fit_cr = np.polyfit(ploty*ym_per_pix, left_fitx*xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(ploty*ym_per_pix, right_fitx*xm_per_pix, 2)    \n",
    "    \n",
    "    y_eval = np.max(ploty)\n",
    "    \n",
    "    ##### TO-DO: Implement the calculation of R_curve (radius of curvature) #####\n",
    "    left_curverad = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "    right_curverad = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "    \n",
    "    if left_curverad > 1500 or right_curverad > 1500:\n",
    "        vehicle_curverad = 0\n",
    "        direction = \"straight line\"        \n",
    "    \n",
    "    else:\n",
    "    \n",
    "    \n",
    "        if left_curverad > right_curverad :\n",
    "            vehicle_curverad = ((left_curverad - right_curverad)/2 )+ right_curverad\n",
    "            direction = \"to right\"\n",
    "        \n",
    "        elif left_curverad < right_curverad :\n",
    "            vehicle_curverad = ((right_curverad - left_curverad )/2) + left_curverad \n",
    "            direction = \"to left\"  \n",
    "              \n",
    "        else:\n",
    "            vehicle_curverad = 0\n",
    "            direction = \"straight line\"          \n",
    "        \n",
    "    return  vehicle_curverad , direction ,left_fitx , right_fitx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_offset(img,left_fitx , right_fitx,width_in_pixels):\n",
    "    \n",
    "    imshape = img.shape\n",
    "\n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "    xm_per_pix = float(3.7/lane_line_width_pixels) # meters per pixel in x dimension      \n",
    "        \n",
    "    left_fitx_pos = left_fitx[700]\n",
    "    right_fitx_pos = right_fitx[700]\n",
    "    lane_line_center = ((right_fitx_pos - left_fitx_pos)/2)+ left_fitx_pos\n",
    "\n",
    "    if lane_line_center > imshape[1]/2:\n",
    "        offset = (lane_line_center - imshape[1]/2)* xm_per_pix\n",
    "        position = \"to left\"\n",
    "    elif lane_line_center < imshape[1]/2:\n",
    "        offset = (imshape[1]/2 - lane_line_center)* xm_per_pix\n",
    "        position = \"to Right\" \n",
    "  \n",
    "       \n",
    "    else:\n",
    "        offset = 0\n",
    "        position = \"In the middle\"         \n",
    "    \n",
    "    return abs(offset) , position  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # Adding information on the pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_info(img , vehicle_curverad , direction,offset,position):\n",
    "    \n",
    "    font = cv2.FONT_HERSHEY_COMPLEX_SMALL\n",
    "    text1 = 'vehicle turn radius: ' + '{:04.1f}'.format(vehicle_curverad) + 'm' + ' to {}'.format(direction)\n",
    "    cv2.putText(img, text1, (40,50), font, 1.5, (255,255,255), 2, cv2.LINE_AA)\n",
    "    text2 = 'Offset vehicle on the lane: ' + '{:.2f}'.format(abs(offset)) + 'm' + ' to {}'.format(position)\n",
    "    cv2.putText(img, text2, (40,100), font, 1.5, (255,255,255), 2, cv2.LINE_AA)\n",
    "    \n",
    "    return img   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "images = glob.glob('test_images/*.jpg')\n",
    "\n",
    "for idx, fname in enumerate(images):\n",
    "\n",
    "    img = mpimg.imread (fname)\n",
    "    undist,binary_warped = Pipeline_warped_binary (img)\n",
    "    left_fit,right_fit,ploty , left_fitx , right_fitx,out_img = fit_polynomial(binary_warped)\n",
    "    \n",
    "    result = draw_lines(binary_warped ,ploty , left_fitx , right_fitx)\n",
    "\n",
    "    offset , position = measure_offset(undist,left_fitx , right_fitx,lane_line_width_pixels)\n",
    "    vehicle_curverad , direction ,left_fitx , right_fitx = measure_curvature_real()\n",
    "        \n",
    "    \n",
    "    img_text = add_info(result , vehicle_curverad , direction,offset,position)\n",
    "    \n",
    "    f, (ax1, ax2) = plt.subplots(1,2, figsize=(24, 8))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(img)\n",
    "    ax1.set_title('Original image -'+ str(fname[12:]), fontsize=30)\n",
    "    ax2.imshow(img_text)\n",
    "    ax2.set_title('Added Lines + Information', fontsize=30)\n",
    "\n",
    "    #You may also uncomment the following line for generate output files    \n",
    "    #plt.savefig('output_images/final_images/'+'final_images_'+fname[12:])    \n",
    "    \n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting Data to support the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_pickle = {}\n",
    "\n",
    "dist_pickle[\"mtx\"] = mtx\n",
    "dist_pickle[\"dist\"] = dist\n",
    "dist_pickle[\"M\"] = M\n",
    "dist_pickle[\"Minv\"] = Minv\n",
    "dist_pickle[\"lane_line_width_pixels\"] = lane_line_width_pixels\n",
    "dist_pickle[\"imshape\"] = imshape\n",
    "\n",
    "pickle.dump( dist_pickle, open( 'test_images/info_data.p', \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
